= A Day in Java Developer's Life, with a taste of Kubernetes
:toc:

Deploying your Java application in a Kubernetes cluster could feel like Alice in Wonderland. You keep going down the rabbit hole and don't know how to make that ride comfortable. This repository explains how a Java application consisting of three  microservices can be deployed in a Kubernetes cluster.

== Microservices

The three microservices are:

. `webapp`: Web application microservice calls `greeting` and `name` microservice to generate a greeting for a person.
. `greeting`: A microservice that returns a greeting.
. `name`: A microservice that returns a person’s name based upon `{id}` in the URL.

== Build and Test Services using Maven

. Each microservice is in a different repo:
+
[cols="1,3"]
|====
| `greeting` | https://github.com/arun-gupta/microservices-greeting
| `name` | https://github.com/arun-gupta/microservices-name
| `webapp` | https://github.com/arun-gupta/microservices-webapp
|====
+
. Clone all the repos. Open each one in a separate terminal.
. Run `greeting` service:
+
	mvn wildfly-swarm:run
+
Test:
+
	curl http://localhost:8081/resources/greeting
+
. Run `name` service:
+
	mvn wildfly-swarm:run
+
Test:
+
	curl http://localhost:8082/resources/names
	curl http://localhost:8082/resources/names/1
+
. Run `webapp` service:

	mvn wildfly-swarm:run

. Run the application:

	curl http://localhost:8080/

== Package as Docker image

=== Create Docker Images

`mvn package -Pdocker` for each repo will create the Docker image.

By default, the Docker image name is `arungupta/<service>` where `<service>` is `greeting`, `name` or `webapp`. The image can be created in your repo:

  mvn package -Pdocker -Ddocker.repo=<repo>

By default, the `latest` tag is used for the image. A different tag may be specified as:

  mvn package -Pdocker -Ddocker.tag=<tag>

=== Push Docker Images to Registry

Push Docker images to the registry:

  mvn install -Pdocker

== Test in Local Environment

Kubernetes can be easily enabled on a development machine using Docker for Mac as explained at https://docs.docker.com/docker-for-mac/#kubernetes.

. Configure kubectl CLI for Kubernetes cluster

	kubectl config use-context docker-for-desktop

. Install the Helm CLI:
+
	brew install kubernetes-helm
+
If Helm CLI is already installed then use `brew upgrade kubernetes-helm`.
+
. Install Helm in Kubernetes cluster:
+
	helm init
+
If Helm has already been initialized on the cluster then you may have to upgrade Tiller:
+
	helm init --upgrade
+
. Install the Helm chart:
+
	helm install --name myapp manifests/myapp
+
By default, the `latest` tag for an image is used. Alternatively, a different tag for the image can be used:
+
  helm install --name myapp apps/k8s/helm/myapp --set "docker.tag=<tag>"
+
. Access the application:

  curl http://$(kubectl get svc/myapp-webapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

. Delete the Helm chart:

	helm delete --purge myapp

== Attach Debugger

== Kubernetes Cluster on AWS

=== Kops Cluster

. Set AZs:
+
```
export AWS_AVAILABILITY_ZONES="$(aws ec2 describe-availability-zones \
	--query 'AvailabilityZones[].ZoneName' \
	--output text | \
	awk -v OFS="," '$1=$1')"
```
+
. Set state store: `export KOPS_STATE_STORE=s3://kubernetes-aws-io`
. Create cluster:

  kops create cluster \
	--zones ${AWS_AVAILABILITY_ZONES} \
	--master-size m4.xlarge \
	--master-zones ${AWS_AVAILABILITY_ZONES} \
	--node-count 5 \
	--node-size m4.2xlarge \
	--name cluster.k8s.local \
	--yes

=== EKS Cluster

== Migrate from Dev to Prod

== Istio

=== Install and Configure

. Enable admission controllers as explained at https://istio.io/docs/setup/kubernetes/quick-start/#aws-w-kops. Rolling update the cluster to enable admission controllers.
. Install and configure:

	curl -L https://github.com/istio/istio/releases/download/0.8.0/istio-0.8.0-osx.tar.gz | tar xzvf -
	cd istio-0.8.0
	export PATH=$PWD/bin:$PATH
	kubectl apply -f install/kubernetes/istio-demo.yaml

. Verify:
+
```
$ kubectl get pods -n istio-system
NAME                                        READY     STATUS      RESTARTS   AGE
grafana-cd99bf478-mcbpw                     1/1       Running     0          15m
istio-citadel-ff5696f6f-fqfcg               1/1       Running     0          15m
istio-cleanup-old-ca-wszns                  0/1       Completed   0          15m
istio-egressgateway-58d98d898c-27mbj        1/1       Running     0          15m
istio-ingressgateway-6bc7c7c4bc-rqjfn       1/1       Running     0          15m
istio-mixer-post-install-dzn6w              0/1       Completed   0          15m
istio-pilot-6c5c6b586c-lrtxf                2/2       Running     0          15m
istio-policy-5c7fbb4b9f-rwzv7               2/2       Running     0          15m
istio-sidecar-injector-dbd67c88d-mgtvn      1/1       Running     0          15m
istio-statsd-prom-bridge-6dbb7dcc7f-gtfz2   1/1       Running     0          15m
istio-telemetry-54b5bf4847-zmlsb            2/2       Running     0          15m
istio-tracing-67dbb5b89f-lg7tp              1/1       Running     0          15m
prometheus-586d95b8d9-zc7bp                 1/1       Running     0          15m
servicegraph-6d86dfc6cb-6pggg               1/1       Running     0          15m
```
+
. Enable sidecar injection for the `default` namespace:

  kubectl label namespace default istio-injection=enabled

. Deploy the application:

  kubectl apply -f manifests/app.yaml

. Check the pods and note that each pod has two containers (one for application and one sidecar) running:

  $ kubectl get pods
  NAME                       READY     STATUS    RESTARTS   AGE
  greeting-fdb644b54-q6z6f   2/2       Running   0          5m
  name-6b98d566bf-khmp6      2/2       Running   0          5m
  webapp-6f4546695d-tnsf8    2/2       Running   0          5m

. Get response:

  curl http://$(kubectl get svc/webapp -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

=== Traffic Shifting and A/B Deployment using Istio

=== Distributed Tracing using Istio

Istio is deployed as a sidecar proxy into each of your pods; this means it can see and monitor all the traffic flows between your microservices and generate a graphical representation of your mesh traffic. We’ll use the application you deployed in the previous step to demonstrate this.

Setup access to the tracing dashboard URL using port-forwarding:

	kubectl port-forward \
		-n istio-system \
		$(kubectl get pod \
			-n istio-system \
			-l app=jaeger \
			-o jsonpath='{.items[0].metadata.name}') 16686:16686 &

Access the dashboard at http://localhost:16686.

image::images/istio-dag.png[]

== Deployment Pipeline

== Alexa Skill to Scale the Application


